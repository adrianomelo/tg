% !TEX encoding = ISO-8859-1
%\chapter{Conclusão e trabalhos futuros}
%\label{ch:conclusaoetrabalhosfuturos}

\section{Conclusão}
Os resultados de boa performance do leanCoP para lógica de primeira ordem dão indícios que o método das conexões pode ganhar espaço entre os métodos de prova para lógica de descrição. Como a w3c \footnote{site: http://w3.org} ainda não definiu uma tecnologia padrão para a camada de lógica e prova da Web Semântica, trabalhos como o que este está inserido são de importância estratégica para a Web, eles desenvolvem soluções que poderão ser adotados em larga escala pelo mundo.

O leanCoP foi envolvido neste trabalho para realizar atividades de raciocínio, como subsunção e equivalência, após a normalização da base de conhecimento. O leanCoP é escrito em Prolog e as APIs de manipulação de ontologias OWL são escritas em Java. Para fazer o leanCoP usar como base de conhecimento as ontologias OWL normalizadas, foi utilizado o formato TPTP como linguagem intermediária. Porém, para fazer as atividades de raciocínio de forma automática, um número exponencial de arquivos deveriam ser gerados em TPTP para serem usados com o leanCoP. Além disso, um trabalho de \textit{parsing} desses arquivos deveria ser realizado para adicionar cada consulta à base de conhecimento de cada arquivo, o que se mostrou fora do escopo do projeto. O leanCoP foi utilizado então para fazer simples checagem de consistência na base de conhecimento, que traz como efeito colateral a validação da corretude do algoritmo de normalização.

Na proposta inicial deste trabalho estava prevista a implementação do algoritmo de normalização de Freitas et al \cite{Freitas:2010}, porém, apesar do algoritmo não incluir novos símbolos à base de conhecimento, não é fácil de ser entendido. A seção 3.1.1 mostra em pseudo-código a implementação que foi feita neste trabalho. O algoritmo foi produzido devido a uma provocação de simplificar o algoritmo de Freitas et al \cite{Freitas:2010}. O objetivo dos algoritmos é o mesmo, traduzir os axiomas de uma ontologia ALC para a forma normal positiva, mas o algoritmo da seção 3.1.1 além de ser mais simples de ser implementado, faz a matriz gerada após a normalização consumir menos memória, o que foi uma grande contribuição. A redução do uso de memória vai impactar no tempo de execução do método das conexões para lógica de descrição, já que a busca pelos caminhos na matriz vai ser reduzido.

\section{Trabalhos futuros}

Este trabalho não contempla todos os constructos de OWL, nem sequer de OWL Lite, já que é limitada à familia ALC. Trabalhos futuros serão para estender o algoritmo de normalização para incluir restrições com cardinalidade, domínio e contradomínio de propriedades, disjunção entre classes e assim por diante.

Este trabalho é apenas um dos módulos necessários para a implementação de um raciocinador escrito em java que use o método das conexões. O algoritmo em si que procura pelas conexões, ou caminhos, ainda não foi implementado.

E, por fim, quando o método das conexões estiver formalizado para uma família de DL que seja equivalente a uma família de OWL e a sua implementação estiver finalizada, poderá haver um trabalho para integrar o raciocinador a editores de ontologias existentes no mercado, como o Protégé.

